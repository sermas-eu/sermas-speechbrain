networks:
  sermas_dev:


services:
  speechbrain:
    image: sermas/speechbrain
    restart: unless-stopped
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./data/models:/app/speechbrain_models
      - ./data/cache/torch:/root/.cache/torch
      - ./data/cache/huggingface:/root/.cache/huggingface
      - ./data/data/torch:/data
      - ./sermas_speechbrain:/app/sermas_speechbrain
      - ./.env:/app/sermas_speechbrain/.env
    networks:
      - sermas_dev
    # This allow you to call the speechbrain service outside of docker compose
    ports:
      - 5011:5011
    # Comment the next section if you do not have an NVIDIA GPU available    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
